<!DOCTYPE html>
<html lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>OpenTrackIO</title>
<link rel="stylesheet" href="css/style.css">
<link rel="apple-touch-icon" sizes="180x180" href="res/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="res/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="res/favicon-16x16.png">
<link rel="manifest" href="res/site.webmanifest">
<link rel="mask-icon" href="res/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
 </head>
<body>
    <div class="header">
        <div class="headerInner">
            <a href="https://www.smpte.org/"><img src="img/logo_white.svg" class="headerLogo" /></a>
            <h1>OpenTrackIO Documentation v(0, 9, 1)</h1>
        </div>
    </div>
    <div class="wrapper">
        <div class="inner">
            <h2>Overview</h2>
            <p>OpenTrackIO is a free and open-source protocol designed by the SMPTE RiS-OSVP group that seeks to improve interoperability in Virtual Production and beyond.</p>
            <p>Virtual Production (VP) encompasses a range of techniques that use camera and lens tracking systems to generate real-time visual effects (VFX) in a render engine. VP encompasses:</p>
            <ul>
                <li>Augmented Reality (AR),</li>
                <li>Chroma key (both for live broadcast and 'Simul-Cam' for on-set VFX pre-visualization),</li>
                <li>In-Camera Visual Effects (ICVFX), eXtended Reality (XR for LED set extensions) and other Mixed Reality (MR) combinations.</li>
            </ul>
            <p>In these Virtual Production examples the camera tracking system sends the pose of the camera, lens modeling and other metadata to a render engine every frame.</p>
            <img src="img/Example_System.svg" />
            <p>In Augmented Reality (AR) setups, this enables the render engine to generate virtual objects from the correct camera position and with correct lens distortions to match the real world camera image. In the In-Camera Visual Effect (ICVFX) example, the tracking data is used to render the correct perspective on the LED wall to create the illusion of depth and with a sense parallax.</p>
            <p>In Virtual Production it is critical that the camera capture, the tracking data, and the lens data are synchronized in space and time to accurately reproduce the visual effect. A sample of the OpenTrackIO protocol contains all the required data in the appropriate formats to achieve this.</p>
            
            <h2>The OpenTrackIO protocol</h2>
            <p>This documentation is designed for those producing and consuming tracking data. Components that generate and transmit tracking data are referred to as Producers. Components that receive and act upon tracking data are referred to as Consumers. Multiple Producers and Consumers may coexist on the same network at the same time, and a Producer can send multiple concurrent streams of data. There may also be multiple Consumers of a single Producer's data. In the AR example above, the camera tracking system is the Producer and the render engine is the Consumer.</p>
            <p>OpenTrackIO defines the schema of JSON samples that contain a wide range of metadata about the device, its transform(s), associated camera and lens. The full schema is given <a href="#schema">below</a> and can be <a href="schema.json" target="_blank">downloaded here</a>.</p>
            <p>All the fields described should be considered optional by the Consumer (although for high-quality tracking for Virtual Production see the recommended set of fields in the samples <a href="#recommended">below</a>).</p>
            <p>OpenTrackIO employs a right-handed coordinate system where the Z-axis points upwards and positive rotations are clockwise around the axis. Y points in the forward camera direction (when pan, tilt and roll are zero). For example, in an LED volume Y would point towards the centre of the LED wall and X would point towards camera-right.</p>
            <p>OpenTrackIO employs the <a href="res/OpenLensIO_v0_9_0.pdf" target="_blank">OpenLensIO mathematical lens model</a> for the practical application of spherical lens distortion in Virtual Production.</p>
            <img class="img-inline" src="img/Coordinate_System.svg" /><img class="img-inline" src="img/Axis_Rotation.svg" /></span>
            
            <h2>Software resources</h2>
            <p>OpenTrackIO's parameters are defined by <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit" target="_blank">CamDKit</a>. This repository includes examples for <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit/tree/main/src/main/python/camdkit/mosys" target="_blank">generating</a> and parsing data in <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit/tree/main/src/test/python/parser" target="_blank">python</a> and <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit/tree/main/src/test/cpp/opentrackio-parser" target="_blank">C++</a>.</p>
            <p>A C++ reference implementation of OpenTrackIO is available on <a href="https://github.com/mosys/opentrackio-cpp" target="_blank">Mo-Sys' GitHub</a> and a C++ port of the python parser is provided in <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit/tree/main/src/test/cpp/opentrackio-parser" target="_blank">CamDKit</a> that demonstrates linkage.</p>

            <h2 id="recommended">OpenTrackIO sample</h2>
            <p>It is recommended that metadata samples are transmitted every frame (i.e. to coincide with the video frames from a camera). It provides a snapshot of the status of the tracking system at that instant.</p>
            <button class="collapsible">Recommended minimum VP example</button>
            <div class="content">
                <pre><code>{
  &#34;lens&#34;: {
    &#34;distortion&#34;: [
      {
        &#34;radial&#34;: [
          1.0,
          2.0,
          3.0
        ],
        &#34;tangential&#34;: [
          1.0,
          2.0
        ]
      }
    ],
    &#34;encoders&#34;: {
      &#34;focus&#34;: 0.1,
      &#34;iris&#34;: 0.2,
      &#34;zoom&#34;: 0.3
    },
    &#34;entrancePupilOffset&#34;: 0.123,
    &#34;fStop&#34;: 4.0,
    &#34;focalLength&#34;: 24.305,
    &#34;focusDistance&#34;: 10.0,
    &#34;projectionOffset&#34;: {
      &#34;x&#34;: 0.1,
      &#34;y&#34;: 0.2
    }
  },
  &#34;protocol&#34;: {
    &#34;name&#34;: &#34;OpenTrackIO&#34;,
    &#34;version&#34;: [
      0,
      9,
      1
    ]
  },
  &#34;sampleId&#34;: &#34;urn:uuid:45c4d3bd-c444-4b22-8d05-9498b2961084&#34;,
  &#34;sourceId&#34;: &#34;urn:uuid:d7ebe9d2-e610-453b-bab4-aba52c34bb58&#34;,
  &#34;sourceNumber&#34;: 1,
  &#34;timing&#34;: {
    &#34;mode&#34;: &#34;external&#34;,
    &#34;sampleRate&#34;: {
      &#34;num&#34;: 24000,
      &#34;denom&#34;: 1001
    },
    &#34;timecode&#34;: {
      &#34;hours&#34;: 1,
      &#34;minutes&#34;: 2,
      &#34;seconds&#34;: 3,
      &#34;frames&#34;: 4,
      &#34;format&#34;: {
        &#34;frameRate&#34;: {
          &#34;num&#34;: 24000,
          &#34;denom&#34;: 1001
        }
      }
    }
  },
  &#34;tracker&#34;: {
    &#34;notes&#34;: &#34;Example generated sample.&#34;,
    &#34;recording&#34;: false,
    &#34;slate&#34;: &#34;A101_A_4&#34;,
    &#34;status&#34;: &#34;Optical Good&#34;
  },
  &#34;transforms&#34;: [
    {
      &#34;translation&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;rotation&#34;: {
        &#34;pan&#34;: 180.0,
        &#34;tilt&#34;: 90.0,
        &#34;roll&#34;: 45.0
      },
      &#34;id&#34;: &#34;Camera&#34;
    }
  ]
}</code></pre>
                <p><a href="examples/recommended_dynamic_example.json" target="_blank">Download</a></p>
            </div>

            <h2>Providing additional static data</h2>
            <p>It is recommended that a static metadata object is added to a sample approximately every 2 seconds. This additional metadata describes the context of the samples in the source, with data that may change - for example - every take, but will not change every frame.</p>
            <button class="collapsible">Recommended minimum VP example with static data</button>
            <div class="content">
                <pre><code>{
  &#34;static&#34;: {
    &#34;camera&#34;: {
      &#34;activeSensorPhysicalDimensions&#34;: {
        &#34;height&#34;: 24.0,
        &#34;width&#34;: 36.0
      },
      &#34;label&#34;: &#34;A&#34;
    },
    &#34;lens&#34;: {
      &#34;make&#34;: &#34;LensMaker&#34;,
      &#34;model&#34;: &#34;Model15&#34;
    }
  },
  &#34;lens&#34;: {
    &#34;distortion&#34;: [
      {
        &#34;radial&#34;: [
          1.0,
          2.0,
          3.0
        ],
        &#34;tangential&#34;: [
          1.0,
          2.0
        ]
      }
    ],
    &#34;encoders&#34;: {
      &#34;focus&#34;: 0.1,
      &#34;iris&#34;: 0.2,
      &#34;zoom&#34;: 0.3
    },
    &#34;entrancePupilOffset&#34;: 0.123,
    &#34;fStop&#34;: 4.0,
    &#34;focalLength&#34;: 24.305,
    &#34;focusDistance&#34;: 10.0,
    &#34;projectionOffset&#34;: {
      &#34;x&#34;: 0.1,
      &#34;y&#34;: 0.2
    }
  },
  &#34;protocol&#34;: {
    &#34;name&#34;: &#34;OpenTrackIO&#34;,
    &#34;version&#34;: [
      0,
      9,
      1
    ]
  },
  &#34;sampleId&#34;: &#34;urn:uuid:aadd65f1-9c1e-49cf-b2ce-f5535cb7ae0e&#34;,
  &#34;sourceId&#34;: &#34;urn:uuid:f474dec9-c2a4-4c72-81f1-5a65620f8fe3&#34;,
  &#34;sourceNumber&#34;: 1,
  &#34;timing&#34;: {
    &#34;mode&#34;: &#34;external&#34;,
    &#34;sampleRate&#34;: {
      &#34;num&#34;: 24000,
      &#34;denom&#34;: 1001
    },
    &#34;timecode&#34;: {
      &#34;hours&#34;: 1,
      &#34;minutes&#34;: 2,
      &#34;seconds&#34;: 3,
      &#34;frames&#34;: 4,
      &#34;format&#34;: {
        &#34;frameRate&#34;: {
          &#34;num&#34;: 24000,
          &#34;denom&#34;: 1001
        }
      }
    }
  },
  &#34;tracker&#34;: {
    &#34;notes&#34;: &#34;Example generated sample.&#34;,
    &#34;recording&#34;: false,
    &#34;slate&#34;: &#34;A101_A_4&#34;,
    &#34;status&#34;: &#34;Optical Good&#34;
  },
  &#34;transforms&#34;: [
    {
      &#34;translation&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;rotation&#34;: {
        &#34;pan&#34;: 180.0,
        &#34;tilt&#34;: 90.0,
        &#34;roll&#34;: 45.0
      },
      &#34;id&#34;: &#34;Camera&#34;
    }
  ]
}</code></pre>
                <p><a href="examples/recommended_static_example.json" target="_blank">Download</a></p>
            </div>

            <h2>Complete sample</h2>
            <p>OpenTrackIO defines many more options and fields and these should be parsed where appropriate by the Consumer. Custom fields can also be added as shown (although these will require specific Producer / Consumer negotiation)</p>
            <button class="collapsible">Complete example sample with static data</button>
            <div class="content">
                <pre><code>{
  &#34;static&#34;: {
    &#34;camera&#34;: {
      &#34;activeSensorPhysicalDimensions&#34;: {
        &#34;height&#34;: 24.0,
        &#34;width&#34;: 36.0
      },
      &#34;activeSensorResolution&#34;: {
        &#34;height&#34;: 2160,
        &#34;width&#34;: 3840
      },
      &#34;anamorphicSqueeze&#34;: {
        &#34;num&#34;: 1,
        &#34;denom&#34;: 1
      },
      &#34;firmwareVersion&#34;: &#34;1.2.3&#34;,
      &#34;label&#34;: &#34;A&#34;,
      &#34;make&#34;: &#34;CameraMaker&#34;,
      &#34;model&#34;: &#34;Model20&#34;,
      &#34;serialNumber&#34;: &#34;1234567890A&#34;,
      &#34;captureFrameRate&#34;: {
        &#34;num&#34;: 24000,
        &#34;denom&#34;: 1001
      },
      &#34;fdlLink&#34;: &#34;urn:uuid:f422c420-db6e-48b9-87c0-3cce054a14d6&#34;,
      &#34;isoSpeed&#34;: 4000,
      &#34;shutterAngle&#34;: 45.0
    },
    &#34;duration&#34;: {
      &#34;num&#34;: 1,
      &#34;denom&#34;: 25
    },
    &#34;lens&#34;: {
      &#34;distortionIsProjection&#34;: true,
      &#34;distortionOverscanMax&#34;: 1.2,
      &#34;make&#34;: &#34;LensMaker&#34;,
      &#34;model&#34;: &#34;Model15&#34;,
      &#34;nominalFocalLength&#34;: 14.0,
      &#34;serialNumber&#34;: &#34;1234567890A&#34;,
      &#34;undistortionOverscanMax&#34;: 1.3
    },
    &#34;tracker&#34;: {
      &#34;firmwareVersion&#34;: &#34;1.2.3&#34;,
      &#34;make&#34;: &#34;TrackerMaker&#34;,
      &#34;model&#34;: &#34;Tracker&#34;,
      &#34;serialNumber&#34;: &#34;1234567890A&#34;
    }
  },
  &#34;globalStage&#34;: {
    &#34;E&#34;: 100.0,
    &#34;N&#34;: 200.0,
    &#34;U&#34;: 300.0,
    &#34;lat0&#34;: 100.0,
    &#34;lon0&#34;: 200.0,
    &#34;h0&#34;: 300.0
  },
  &#34;lens&#34;: {
    &#34;custom&#34;: [
      1.0,
      2.0
    ],
    &#34;distortionOffset&#34;: {
      &#34;x&#34;: 1.0,
      &#34;y&#34;: 2.0
    },
    &#34;distortionOverscan&#34;: 1.1,
    &#34;distortion&#34;: [
      {
        &#34;radial&#34;: [
          1.0,
          2.0,
          3.0,
          4.0,
          5.0,
          6.0
        ],
        &#34;tangential&#34;: [
          1.0,
          2.0
        ],
        &#34;model&#34;: &#34;Brown-Conrady D-U&#34;
      },
      {
        &#34;radial&#34;: [
          1.0,
          2.0,
          3.0,
          4.0,
          5.0,
          6.0
        ],
        &#34;tangential&#34;: [
          1.0,
          2.0
        ],
        &#34;model&#34;: &#34;Brown-Conrady U-D&#34;
      }
    ],
    &#34;encoders&#34;: {
      &#34;focus&#34;: 0.1,
      &#34;iris&#34;: 0.2,
      &#34;zoom&#34;: 0.3
    },
    &#34;entrancePupilOffset&#34;: 0.123,
    &#34;exposureFalloff&#34;: {
      &#34;a1&#34;: 1.0,
      &#34;a2&#34;: 2.0,
      &#34;a3&#34;: 3.0
    },
    &#34;fStop&#34;: 4.0,
    &#34;focalLength&#34;: 24.305,
    &#34;focusDistance&#34;: 10.0,
    &#34;projectionOffset&#34;: {
      &#34;x&#34;: 0.1,
      &#34;y&#34;: 0.2
    },
    &#34;rawEncoders&#34;: {
      &#34;focus&#34;: 1000,
      &#34;iris&#34;: 2000,
      &#34;zoom&#34;: 3000
    },
    &#34;tStop&#34;: 4.1,
    &#34;undistortionOverscan&#34;: 1.2
  },
  &#34;protocol&#34;: {
    &#34;name&#34;: &#34;OpenTrackIO&#34;,
    &#34;version&#34;: [
      0,
      9,
      1
    ]
  },
  &#34;relatedSampleIds&#34;: [
    &#34;urn:uuid:21b04865-5f47-4837-a585-5e946411f0f3&#34;,
    &#34;urn:uuid:a64139cb-801b-40f0-af1f-218de4775282&#34;
  ],
  &#34;sampleId&#34;: &#34;urn:uuid:e518b5db-0b6f-42f2-8288-435989ec4598&#34;,
  &#34;sourceId&#34;: &#34;urn:uuid:e02e3150-8f69-430c-acce-2c8db25eebea&#34;,
  &#34;sourceNumber&#34;: 1,
  &#34;timing&#34;: {
    &#34;mode&#34;: &#34;internal&#34;,
    &#34;recordedTimestamp&#34;: {
      &#34;seconds&#34;: 1718806000,
      &#34;nanoseconds&#34;: 500000000
    },
    &#34;sampleRate&#34;: {
      &#34;num&#34;: 24000,
      &#34;denom&#34;: 1001
    },
    &#34;sampleTimestamp&#34;: {
      &#34;seconds&#34;: 1718806554,
      &#34;nanoseconds&#34;: 500000000
    },
    &#34;sequenceNumber&#34;: 0,
    &#34;synchronization&#34;: {
      &#34;locked&#34;: true,
      &#34;source&#34;: &#34;ptp&#34;,
      &#34;frequency&#34;: {
        &#34;num&#34;: 24000,
        &#34;denom&#34;: 1001
      },
      &#34;offsets&#34;: {
        &#34;translation&#34;: 1.0,
        &#34;rotation&#34;: 2.0,
        &#34;lensEncoders&#34;: 3.0
      },
      &#34;present&#34;: true,
      &#34;ptp&#34;: {
        &#34;domain&#34;: 1,
        &#34;leader&#34;: &#34;00:11:22:33:44:55&#34;,
        &#34;offset&#34;: 0.0
      }
    },
    &#34;timecode&#34;: {
      &#34;hours&#34;: 1,
      &#34;minutes&#34;: 2,
      &#34;seconds&#34;: 3,
      &#34;frames&#34;: 4,
      &#34;format&#34;: {
        &#34;frameRate&#34;: {
          &#34;num&#34;: 24000,
          &#34;denom&#34;: 1001
        }
      }
    }
  },
  &#34;tracker&#34;: {
    &#34;notes&#34;: &#34;Example generated sample.&#34;,
    &#34;recording&#34;: false,
    &#34;slate&#34;: &#34;A101_A_4&#34;,
    &#34;status&#34;: &#34;Optical Good&#34;
  },
  &#34;transforms&#34;: [
    {
      &#34;translation&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;rotation&#34;: {
        &#34;pan&#34;: 180.0,
        &#34;tilt&#34;: 90.0,
        &#34;roll&#34;: 45.0
      },
      &#34;id&#34;: &#34;Dolly&#34;
    },
    {
      &#34;translation&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;rotation&#34;: {
        &#34;pan&#34;: 180.0,
        &#34;tilt&#34;: 90.0,
        &#34;roll&#34;: 45.0
      },
      &#34;scale&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;id&#34;: &#34;Crane Arm&#34;
    },
    {
      &#34;translation&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;rotation&#34;: {
        &#34;pan&#34;: 180.0,
        &#34;tilt&#34;: 90.0,
        &#34;roll&#34;: 45.0
      },
      &#34;scale&#34;: {
        &#34;x&#34;: 1.0,
        &#34;y&#34;: 2.0,
        &#34;z&#34;: 3.0
      },
      &#34;id&#34;: &#34;Camera&#34;
    }
  ],
  &#34;custom&#34;: {
    &#34;pot1&#34;: 2435,
    &#34;button1&#34;: false
  }
}</code></pre>
                <p><a href="examples/complete_static_example.json" target="_blank">Download</a></p>
            </div>
            
            <h2>Transport recommendations</h2>
            <h3>UDP</h3>
            <p>OpenTrackIO typically operates over IPv4 UDP. Support for IPv6 is not included in the current version of OpenTrackIO. When using IPv4 UDP, the below guidelines have been put in place to ensure interoperability between systems.</p>
            <h4>IP Addressing</h4>
            <p>It is recommended that OpenTrackIO Producers use multicast addressing to deliver messages to Consumers to guarantee interoperability and ease of configuration. The use of unicast addressing is also allowed, but implementation details are currently outside the scope of this document.</p>
            
            <p>Producers should transmit multicast messages according to the addressing scheme in the table below.</p>
                
            <table>
                <thead>
                    <tr>
                        <th>IP Octet 1</th>
                        <th>IP Octet 2</th>
                        <th>IP Octet 3</th>
                        <th>IP Octet 4</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>235</td>
                        <td>135</td>
                        <td>1</td>
                        <td>Source Number</td>
                    </tr>
                </tbody>
            </table>
                
            <p>
                The <strong>Source Number</strong> is a user-configurable 8-bit value (1–200) that determines the multicast IP address for a specific Source from a Producer. By embedding the Source Number in the 4th octet of the multicast IP address, this mechanism enables Producers and Consumers to exchange data for a given Source without requiring prior knowledge of the network topology or specific IP addresses.
            </p>
            <p>This design allows:</p>
            <ul>
                <li>A single Producer to transmit multiple Sources to multiple Consumers.</li>
                <li>Consumers to receive multiple data streams over a single network interface.</li>
            </ul>
            
            <h5>Example</h5>
            <p>In the example above, using a Producer with Source Number 14:</p>
            <ul>
                <li><strong>IP Octet 1:</strong> 235</li>
                <li><strong>IP Octet 2:</strong> 135</li>
                <li><strong>IP Octet 3:</strong> 1</li>
                <li><strong>IP Octet 4:</strong> 14</li>
            </ul>
            
            <p>
                The <strong>Source Number</strong> is a configurable, user-assignable value that is unique within an OpenTrackIO network. 
                It identifies a specific Source of data from a particular Producer. The Source Number must be explicitly configured and 
                should <strong>not</strong> be inferred from the multicast address. Source Numbers above <strong>200</strong> are reserved 
                for future expansion of the OpenTrackIO protocol and may not be used. Consumers shall discard any messages containing a 
                Source Number of <strong>0</strong> or <strong>201–255</strong>.
            </p>
            <p>
                The default destination UDP port for multicast messages is <strong>55555</strong>. Other ports may be used if necessary 
                based on local network requirements.
            </p>
            <p>
                Consumers must handle identical multicast messages consistently. If a Consumer receives the same message multiple times, 
                it should process only one instance.
            </p>
            <p>
                OpenTrackIO is a unidirectional protocol; however, if a Consumer receives a message that requires a response, the reply 
                should be sent via unicast to the source address and port of the Producer from which the message originated. Guidelines 
                for when and how devices should respond are outside the scope of the current version of OpenTrackIO, but may be included 
                in a future version.
            </p>
            
            <h4>Multicast Subscription</h4>
            <p>
                Components must implement <strong>IGMP V2</strong> or any subsequent version that supports its functionality. This protocol 
                communicates multicast address usage to the network infrastructure, ensuring correct delivery of multicast traffic across 
                large and complex networks.
            </p>
            
            <h4>Packet Header</h4>
            <p>When using raw UDP or serial transport, each packet should include the header below:</p>
            <p>
                <table>
                  <thead>
                    <tr>
                      <th>Bit Offset</th>
                      <th>Field</th>
                      <th>Description</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>0-31</td>
                      <td>Identifier</td>
                      <td>4 bytes: Static value to indicate OpenTrackIO packet, set to ASCII "OTrk" (<code>0x4F54726B</code>)</td>
                    </tr>
                    <tr>
                      <td>32-39</td>
                      <td>Reserved</td>
                      <td>1 byte: This field is reserved for future use and should be ignored by both Producers and Consumers.</td>
                    </tr>
                    <tr>
                      <td>40-47</td>
                      <td>Encoding</td>
                      <td>1 byte: Indicates the payload format (e.g., JSON = <code>0x01</code>, CBOR = <code>0x02</code>, OTP = <code>0x02</code>). <code>0x80</code> and above are reserved for vendor specific protocols.</td>
                    </tr>
                    <tr>
                      <td>48-63</td>
                      <td>Sequence number</td>
                      <td>1 bytes: Unsigned integer indicating the OpenTrackIO packet's unique sequence number (<code>0x01</code> to <code>UINT16</code>)</td>
                    </tr>
                    <tr>
                      <td>64–95</td>
                      <td>Segment offset</td>
                      <td>4 bytes: A 32-bit field indicating the byte offset of this payload segment when the overall payload length necessitates segmentation. Must be set to <code>0x00</code> for single-segment payloads.</td>
                    </tr>
                    <tr>
                      <td>96</td>
                      <td>Last segment flag</td>
                      <td>This bit shall be set to <code>1</code> if this is the only segment or the last segment in a segmented payload, or<code>0</code> if more segments are expected.</td>
                    </tr>
                    <tr>
                      <td>97–111</td>
                      <td>Payload Length</td>
                      <td>15 bits: Total length of the payload for the current packet (in bytes).</td>
                    </tr>
                    <tr>
                      <td>112–127</td>
                      <td>Checksum (Fletcher16)</td>
                      <td>2 bytes: A 16-bit checksum computed using the Fletcher-16 algorithm, covering the header (excluding checksum bytes) and payload.</td>
                    </tr>
                    <tr>
                      <td>128+</td>
                      <td>Payload</td>
                      <td>The actual JSON or CBOR OpenTrackIO packet (or a segment thereof)  data starts here</td>
                    </tr>
                  </tbody>
                </table>
            </p>
            
            <h2>Description of all fields</h2>
            <button class="collapsible">Description of fields</button>
            <div class="content">
                <table>
                    <tr><th>Parameter</th><th>Section</th><th>Sampling</th><th>Description</th><th>Units</th><th>Constraints</th></tr>
                    
                    <tr><td>activeSensorPhysicalDimensions</td><td>camera</td><td>Static</td><td>Height and width of the active area of the camera sensor in microns</td><td>millimeter</td><td>The height and width shall be each be real non-negative numbers.</td></tr>
                    
                    <tr><td>activeSensorResolution</td><td>camera</td><td>Static</td><td>Photosite resolution of the active area of the camera sensor in pixels</td><td>pixel</td><td>The height and width shall be each be an integer in the range
    [0..2,147,483,647].
    </td></tr>
                    
                    <tr><td>anamorphicSqueeze</td><td>camera</td><td>Static</td><td>Nominal ratio of height to width of the image of an axis-aligned
  square captured by the camera sensor. It can be used to de-squeeze
  images but is not however an exact number over the entire captured
  area due to a lens&#39; intrinsic analog nature.
  </td><td>None</td><td>The parameter shall be a rational number whose numerator
    is in the range [0..2,147,483,647] and denominator in the range
    (0..4,294,967,295].
    </td></tr>
                    
                    <tr><td>firmwareVersion</td><td>camera</td><td>Static</td><td>Non-blank string identifying camera firmware version</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>label</td><td>camera</td><td>Static</td><td>Non-blank string containing user-determined camera identifier</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>make</td><td>camera</td><td>Static</td><td>Non-blank string naming camera manufacturer</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>model</td><td>camera</td><td>Static</td><td>Non-blank string identifying camera model</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>serialNumber</td><td>camera</td><td>Static</td><td>Non-blank string uniquely identifying the camera</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>captureFrameRate</td><td>camera</td><td>Static</td><td>Capture frame rate of the camera</td><td>hertz</td><td>The parameter shall be a rational number whose numerator
    is in the range [0..2,147,483,647] and denominator in the range
    (0..4,294,967,295].
    </td></tr>
                    
                    <tr><td>duration</td><td>None</td><td>Static</td><td>Duration of the clip</td><td>second</td><td>The parameter shall be a rational number whose numerator
    is in the range [0..2,147,483,647] and denominator in the range
    (0..4,294,967,295].
    </td></tr>
                    
                    <tr><td>fdlLink</td><td>camera</td><td>Static</td><td>URN identifying the ASC Framing Decision List used by the camera.</td><td>None</td><td>The parameter shall be a UUID URN as specified in IETF RFC 4122.
    Only lowercase characters shall be used.
    Example: `f81d4fae-7dec-11d0-a765-00a0c91e6bf6`
    </td></tr>
                    
                    <tr><td>globalStage</td><td>None</td><td>Regular</td><td>Position of stage origin in global ENU and geodetic coordinates
  (E, N, U, lat0, lon0, h0). Note this may be dynamic if the stage is
  inside a moving vehicle.
  </td><td>meter</td><td>Each field in the GlobalPosition shall be a real number</td></tr>
                    
                    <tr><td>isoSpeed</td><td>camera</td><td>Static</td><td>Arithmetic ISO scale as defined in ISO 12232</td><td>None</td><td>The parameter shall be a integer in the range (1..4,294,967,295].</td></tr>
                    
                    <tr><td>custom</td><td>lens</td><td>Regular</td><td>This list provides optional additional custom coefficients that can 
  extend the existing lens model. The meaning of and how these characteristics
  are to be applied to a virtual camera would require negotiation between a
  particular producer and consumer.
  </td><td>None</td><td>The parameter shall be a tuple of items of the class itemClass.
    The tuple can be empty
    </td></tr>
                    
                    <tr><td>distortionIsProjection</td><td>lens</td><td>Static</td><td>Indicator that the OpenLensIO distortion model is the Projection
  Characterization, not the Field-Of-View Characterization. This is 
  primarily relevant when storing overscan values, not in transmission
  as the overscan should be calculated by the consumer.
  </td><td>None</td><td>The parameter shall be a boolean.</td></tr>
                    
                    <tr><td>distortionOffset</td><td>lens</td><td>Regular</td><td>Offset in x and y of the centre of distortion of the virtual camera</td><td>millimeter</td><td>X and Y centre shift shall each be real numbers.</td></tr>
                    
                    <tr><td>distortionOverscan</td><td>lens</td><td>Regular</td><td>Overscan factor on lens distortion. This is primarily relevant when
  storing overscan values, not in transmission as the overscan should be
  calculated by the consumer.
  </td><td>None</td><td>The parameter shall be a real number &gt;= 1.</td></tr>
                    
                    <tr><td>distortionOverscanMax</td><td>lens</td><td>Static</td><td>Static maximum overscan factor on lens distortion. This is primarily
  relevant when storing overscan values, not in transmission as the
  overscan should be calculated by the consumer.
  </td><td>None</td><td>The parameter shall be a real number &gt;= 1.</td></tr>
                    
                    <tr><td>distortion</td><td>lens</td><td>Regular</td><td>A list of Distortion objects that each define the coefficients for
  calculating the distortion characteristics of a lens comprising radial
  distortion coefficients of the spherical distortion (k1-N) and the
  tangential distortion (p1-N). An optional key &#39;model&#39; can be used that
  describes the distortion model. The default is Brown-Conrady D-U (that
  maps Distorted to Undistorted coordinates).
  </td><td>None</td><td>The list shall contain at least one Distortion object, and in each
    object the radial and tangential coefficients shall each be real numbers.
    </td></tr>
                    
                    <tr><td>encoders</td><td>lens</td><td>Regular</td><td>Normalised real numbers (0-1) for focus, iris and zoom.
  Encoders are represented in this way (as opposed to raw integer
  values) to ensure values remain independent of encoder resolution,
  minimum and maximum (at an acceptable loss of precision).
  These values are only relevant in lenses with end-stops that
  demarcate the 0 and 1 range.
  Value should be provided in the following directions (if known):
  Focus:   0=infinite     1=closest
  Iris:    0=open         1=closed
  Zoom:    0=wide angle   1=telephoto
  </td><td>None</td><td>
    The parameter shall contain at least one normalised values (0..1) for the FIZ encoders.
    </td></tr>
                    
                    <tr><td>entrancePupilOffset</td><td>lens</td><td>Regular</td><td>Offset of the entrance pupil relative to the nominal imaging plane
  (positive if the entrance pupil is located on the side of the nominal
  imaging plane that is towards the object, and negative otherwise).
  Measured in meters as in a render engine it is often applied in the
  virtual camera&#39;s transform chain.
  </td><td>meter</td><td>The parameter shall be a real number.</td></tr>
                    
                    <tr><td>exposureFalloff</td><td>lens</td><td>Regular</td><td>Coefficients for calculating the exposure fall-off (vignetting) of
  a lens
  </td><td>None</td><td>The coefficients shall each be real numbers.</td></tr>
                    
                    <tr><td>fStop</td><td>lens</td><td>Regular</td><td>The linear f-number of the lens, equal to the focal length divided
  by the diameter of the entrance pupil.
  </td><td>None</td><td>The parameter shall be a non-negative real number.</td></tr>
                    
                    <tr><td>firmwareVersion</td><td>lens</td><td>Static</td><td>Non-blank string identifying lens firmware version</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>focalLength</td><td>lens</td><td>Regular</td><td>Focal length of the lens.</td><td>millimeter</td><td>The parameter shall be a non-negative real number.</td></tr>
                    
                    <tr><td>focusDistance</td><td>lens</td><td>Regular</td><td>Focus distance/position of the lens</td><td>meter</td><td>The parameter shall be a real number greater than 0.</td></tr>
                    
                    <tr><td>make</td><td>lens</td><td>Static</td><td>Non-blank string naming lens manufacturer</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>model</td><td>lens</td><td>Static</td><td>Non-blank string identifying lens model</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>nominalFocalLength</td><td>lens</td><td>Static</td><td>Nominal focal length of the lens. The number printed on the side
  of a prime lens, e.g. 50 mm, and undefined in the case of a zoom lens.
  </td><td>millimeter</td><td>The parameter shall be a real number greater than 0.</td></tr>
                    
                    <tr><td>projectionOffset</td><td>lens</td><td>Regular</td><td>Offset in x and y of the centre of perspective projection of the
  virtual camera
  </td><td>millimeter</td><td>X and Y projection offset shall each be real numbers.</td></tr>
                    
                    <tr><td>rawEncoders</td><td>lens</td><td>Regular</td><td>Raw encoder values for focus, iris and zoom.
  These values are dependent on encoder resolution and before any
  homing / ranging has taken place.
  </td><td>None</td><td>
    The parameter shall contain at least one integer value for the FIZ encoders.
    </td></tr>
                    
                    <tr><td>serialNumber</td><td>lens</td><td>Static</td><td>Non-blank string uniquely identifying the lens</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>tStop</td><td>lens</td><td>Regular</td><td>Linear t-number of the lens, equal to the F-number of the lens
  divided by the square root of the transmittance of the lens.
  </td><td>None</td><td>The parameter shall be a non-negative real number.</td></tr>
                    
                    <tr><td>undistortionOverscan</td><td>lens</td><td>Regular</td><td>Overscan factor on lens undistortion. This is primarily relevant when
  storing overscan values, not in transmission as the overscan should be
  calculated by the consumer.
  </td><td>None</td><td>The parameter shall be a real number &gt;= 1.</td></tr>
                    
                    <tr><td>undistortionOverscanMax</td><td>lens</td><td>Static</td><td>Static maximum overscan factor on lens undistortion. This is primarily
  relevant when storing overscan values, not in transmission as the
  overscan should be calculated by the consumer.
  </td><td>None</td><td>The parameter shall be a real number &gt;= 1.</td></tr>
                    
                    <tr><td>protocol</td><td>None</td><td>Regular</td><td>Name of the protocol in which the sample is being employed, and
  version of that protocol
  </td><td>None</td><td>Protocol name is nonblank string; protocol version is basic x.y.z
    semantic versioning string
    </td></tr>
                    
                    <tr><td>relatedSampleIds</td><td>None</td><td>Regular</td><td>List of sampleId properties of samples related to this sample. The
  existence of a sample with a given sampleId is not guaranteed.
  </td><td>None</td><td>The parameter shall be a tuple of items of the class itemClass.
    The tuple can be empty
    </td></tr>
                    
                    <tr><td>sampleId</td><td>None</td><td>Regular</td><td>URN serving as unique identifier of the sample in which data is
  being transported.
  </td><td>None</td><td>The parameter shall be a UUID URN as specified in IETF RFC 4122.
    Only lowercase characters shall be used.
    Example: `f81d4fae-7dec-11d0-a765-00a0c91e6bf6`
    </td></tr>
                    
                    <tr><td>shutterAngle</td><td>camera</td><td>Static</td><td>Shutter speed as a fraction of the capture frame rate. The shutter
  speed (in units of 1/s) is equal to the value of the parameter divided
  by 360 times the capture frame rate.
  </td><td>degree</td><td>The parameter shall be a real number in the range (0..360].</td></tr>
                    
                    <tr><td>sourceId</td><td>None</td><td>Regular</td><td>URN serving as unique identifier of the source from which data is
  being transported.
  </td><td>None</td><td>The parameter shall be a UUID URN as specified in IETF RFC 4122.
    Only lowercase characters shall be used.
    Example: `f81d4fae-7dec-11d0-a765-00a0c91e6bf6`
    </td></tr>
                    
                    <tr><td>sourceNumber</td><td>None</td><td>Regular</td><td>Number that identifies the index of the stream from a source from which
  data is being transported. This is most important in the case where a source
  is producing multiple streams of samples.
  </td><td>None</td><td>The parameter shall be a integer in the range (0..4,294,967,295].</td></tr>
                    
                    <tr><td>mode</td><td>timing</td><td>Regular</td><td>Enumerated value indicating whether the sample transport mechanism
  provides inherent (&#39;external&#39;) timing, or whether the transport
  mechanism lacks inherent timing and so the sample must contain a PTP
  timestamp itself (&#39;internal&#39;) to carry timing information.
  </td><td>None</td><td>The parameter shall be one of the allowed values.</td></tr>
                    
                    <tr><td>recordedTimestamp</td><td>timing</td><td>Regular</td><td>PTP timestamp of the data recording instant, provided for convenience
  during playback of e.g. pre-recorded tracking data. The timestamp
  comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned
  integer (nanoseconds)
  </td><td>second</td><td>The parameter shall contain valid number of seconds, nanoseconds
    elapsed since the start of the epoch.
    </td></tr>
                    
                    <tr><td>sampleRate</td><td>timing</td><td>Regular</td><td>Sample frame rate as a rational number. Drop frame rates such as
  29.97 should be represented as e.g. 30000/1001. In a variable rate
  system this should is estimated from the last sample delta time.
  </td><td>None</td><td>The parameter shall be a rational number whose numerator
    is in the range [0..2,147,483,647] and denominator in the range
    (0..4,294,967,295].
    </td></tr>
                    
                    <tr><td>sampleTimestamp</td><td>timing</td><td>Regular</td><td>PTP timestamp of the data capture instant. Note this may differ
  from the packet&#39;s transmission PTP timestamp. The timestamp
  comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned
  integer (nanoseconds)
  </td><td>second</td><td>The parameter shall contain valid number of seconds, nanoseconds
    elapsed since the start of the epoch.
    </td></tr>
                    
                    <tr><td>sequenceNumber</td><td>timing</td><td>Regular</td><td>Integer incrementing with each sample.</td><td>None</td><td>The parameter shall be a integer in the range (0..4,294,967,295].</td></tr>
                    
                    <tr><td>synchronization</td><td>timing</td><td>Regular</td><td>Object describing how the tracking device is synchronized for this
  sample.

  frequency: The frequency of a synchronization signal.This may differ from
  the sample frame rate for example in a genlocked tracking device. This is
  not required if the synchronization source is PTP or NTP.
  locked: Is the tracking device locked to the synchronization source
  offsets: Offsets in seconds between sync and sample. Critical for e.g.
  frame remapping, or when using different data sources for
  position/rotation and lens encoding
  present: Is the synchronization source present (a synchronization
  source can be present but not locked if frame rates differ for
  example)
  ptp: If the synchronization source is a PTP leader, then this object
  contains:
  - &#34;leader&#34;: The MAC address of the PTP leader
  - &#34;offset&#34;: The timing offset in seconds from the sample timestamp to
  the PTP timestamp
  - &#34;domain&#34;: The PTP domain number
  source: The source of synchronization must be defined as one of the
  following:
  - &#34;genlock&#34;: The tracking device has an external black/burst or
  tri-level analog sync signal that is triggering the capture of
  tracking samples
  - &#34;videoIn&#34;: The tracking device has an external video signal that is
  triggering the capture of tracking samples
  - &#34;ptp&#34;: The tracking device is locked to a PTP leader
  - &#34;ntp&#34;: The tracking device is locked to an NTP server
  </td><td>None</td><td>The parameter shall contain the required valid fields.</td></tr>
                    
                    <tr><td>timecode</td><td>timing</td><td>Regular</td><td>SMPTE timecode of the sample. Timecode is a standard for labeling
  individual frames of data in media systems and is useful for
  inter-frame synchronization.
  - format.frameRate: The frame rate as a rational number. Drop frame
  rates such as 29.97 should be represented as e.g. 30000/1001. The
  timecode frame rate may differ from the sample frequency.
  </td><td>None</td><td>The parameter shall contain a valid format and hours, minutes,
    seconds and frames with appropriate min/max values.
    </td></tr>
                    
                    <tr><td>firmwareVersion</td><td>tracker</td><td>Static</td><td>Non-blank string identifying tracking device firmware version</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>make</td><td>tracker</td><td>Static</td><td>Non-blank string naming tracking device manufacturer</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>model</td><td>tracker</td><td>Static</td><td>Non-blank string identifying tracking device model</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>notes</td><td>tracker</td><td>Regular</td><td>Non-blank string containing notes about tracking system</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>recording</td><td>tracker</td><td>Regular</td><td>Boolean indicating whether tracking system is recording data</td><td>None</td><td>The parameter shall be a boolean.</td></tr>
                    
                    <tr><td>serialNumber</td><td>tracker</td><td>Static</td><td>Non-blank string uniquely identifying the tracking device</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>slate</td><td>tracker</td><td>Regular</td><td>Non-blank string describing the recording slate</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>status</td><td>tracker</td><td>Regular</td><td>Non-blank string describing status of tracking system</td><td>None</td><td>The parameter shall be a Unicode string between 0 and 1023
    codepoints.
    </td></tr>
                    
                    <tr><td>transforms</td><td>None</td><td>Regular</td><td>A list of transforms.
  Transforms are composed in order with the last in the list representing
  the X,Y,Z in meters of camera sensor relative to stage origin.
  The Z axis points upwards and the coordinate system is right-handed.
  Y points in the forward camera direction (when pan, tilt and roll are
  zero).
  For example in an LED volume Y would point towards the centre of the
  LED wall and so X would point to camera-right.
  Rotation expressed as euler angles in degrees of the camera sensor
  relative to stage origin
  Rotations are intrinsic and are measured around the axes ZXY, commonly
  referred to as [pan, tilt, roll]
  Notes on Euler angles:
  Euler angles are human readable and unlike quarternions, provide the
  ability for cycles (with angles &gt;360 or &lt;0 degrees).
  Where a tracking system is providing the pose of a virtual camera,
  gimbal lock does not present the physical challenges of a robotic
  system.
  Conversion to and from quarternions is trivial with an acceptable loss
  of precision.
  </td><td>meter / degree</td><td>Each component of each transform shall contain Real numbers.</td></tr>
                    
                </table>
            </div>

            <h2 id="schema">JSON schema</h2>
            <p><a href="schema.json" target="_blank">This JSON Schema</a> can be used to validate OpenTrackIO samples</p>
            <button class="collapsible">OpenTrackIO schema</button>
            <div class="content"><pre><code>{
  &#34;$id&#34;: &#34;https://opentrackio.org/schema.json&#34;,
  &#34;$schema&#34;: &#34;https://json-schema.org/draft/2020-12/schema&#34;,
  &#34;type&#34;: &#34;object&#34;,
  &#34;properties&#34;: {
    &#34;static&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;properties&#34;: {
        &#34;camera&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;activeSensorPhysicalDimensions&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;additionalProperties&#34;: false,
              &#34;required&#34;: [
                &#34;height&#34;,
                &#34;width&#34;
              ],
              &#34;properties&#34;: {
                &#34;height&#34;: {
                  &#34;type&#34;: &#34;number&#34;,
                  &#34;minimum&#34;: 0.0
                },
                &#34;width&#34;: {
                  &#34;type&#34;: &#34;number&#34;,
                  &#34;minimum&#34;: 0.0
                }
              },
              &#34;description&#34;: &#34;Height and width of the active area of the camera sensor in microns&#34;,
              &#34;units&#34;: &#34;millimeter&#34;
            },
            &#34;activeSensorResolution&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;additionalProperties&#34;: false,
              &#34;required&#34;: [
                &#34;height&#34;,
                &#34;width&#34;
              ],
              &#34;properties&#34;: {
                &#34;height&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 0,
                  &#34;maximum&#34;: 2147483647
                },
                &#34;width&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 0,
                  &#34;maximum&#34;: 2147483647
                }
              },
              &#34;description&#34;: &#34;Photosite resolution of the active area of the camera sensor in pixels&#34;,
              &#34;units&#34;: &#34;pixel&#34;
            },
            &#34;anamorphicSqueeze&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;properties&#34;: {
                &#34;num&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 2147483647
                },
                &#34;denom&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 4294967295
                }
              },
              &#34;required&#34;: [
                &#34;num&#34;,
                &#34;denom&#34;
              ],
              &#34;additionalProperties&#34;: false,
              &#34;description&#34;: &#34;Nominal ratio of height to width of the image of an axis-aligned square captured by the camera sensor. It can be used to de-squeeze images but is not however an exact number over the entire captured area due to a lens&#39; intrinsic analog nature. &#34;
            },
            &#34;firmwareVersion&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying camera firmware version&#34;
            },
            &#34;label&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string containing user-determined camera identifier&#34;
            },
            &#34;make&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string naming camera manufacturer&#34;
            },
            &#34;model&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying camera model&#34;
            },
            &#34;serialNumber&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string uniquely identifying the camera&#34;
            },
            &#34;captureFrameRate&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;properties&#34;: {
                &#34;num&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 2147483647
                },
                &#34;denom&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 4294967295
                }
              },
              &#34;required&#34;: [
                &#34;num&#34;,
                &#34;denom&#34;
              ],
              &#34;additionalProperties&#34;: false,
              &#34;description&#34;: &#34;Capture frame rate of the camera&#34;,
              &#34;units&#34;: &#34;hertz&#34;
            },
            &#34;fdlLink&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;pattern&#34;: &#34;^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$&#34;,
              &#34;description&#34;: &#34;URN identifying the ASC Framing Decision List used by the camera.&#34;
            },
            &#34;isoSpeed&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 1,
              &#34;maximum&#34;: 4294967295,
              &#34;description&#34;: &#34;Arithmetic ISO scale as defined in ISO 12232&#34;
            },
            &#34;shutterAngle&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 0.0,
              &#34;maximum&#34;: 360.0,
              &#34;description&#34;: &#34;Shutter speed as a fraction of the capture frame rate. The shutter speed (in units of 1/s) is equal to the value of the parameter divided by 360 times the capture frame rate. &#34;,
              &#34;units&#34;: &#34;degree&#34;
            }
          }
        },
        &#34;duration&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;properties&#34;: {
            &#34;num&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 1,
              &#34;maximum&#34;: 2147483647
            },
            &#34;denom&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 1,
              &#34;maximum&#34;: 4294967295
            }
          },
          &#34;required&#34;: [
            &#34;num&#34;,
            &#34;denom&#34;
          ],
          &#34;additionalProperties&#34;: false,
          &#34;description&#34;: &#34;Duration of the clip&#34;,
          &#34;units&#34;: &#34;second&#34;
        },
        &#34;lens&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;distortionIsProjection&#34;: {
              &#34;type&#34;: &#34;boolean&#34;,
              &#34;description&#34;: &#34;Indicator that the OpenLensIO distortion model is the Projection Characterization, not the Field-Of-View Characterization. This is  primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. &#34;
            },
            &#34;distortionOverscanMax&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 1.0,
              &#34;description&#34;: &#34;Static maximum overscan factor on lens distortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. &#34;
            },
            &#34;firmwareVersion&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying lens firmware version&#34;
            },
            &#34;make&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string naming lens manufacturer&#34;
            },
            &#34;model&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying lens model&#34;
            },
            &#34;nominalFocalLength&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;exclusiveMinimum&#34;: 0.0,
              &#34;description&#34;: &#34;Nominal focal length of the lens. The number printed on the side of a prime lens, e.g. 50 mm, and undefined in the case of a zoom lens. &#34;,
              &#34;units&#34;: &#34;millimeter&#34;
            },
            &#34;serialNumber&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string uniquely identifying the lens&#34;
            },
            &#34;undistortionOverscanMax&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 1.0,
              &#34;description&#34;: &#34;Static maximum overscan factor on lens undistortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. &#34;
            }
          }
        },
        &#34;tracker&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;firmwareVersion&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying tracking device firmware version&#34;
            },
            &#34;make&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string naming tracking device manufacturer&#34;
            },
            &#34;model&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string identifying tracking device model&#34;
            },
            &#34;serialNumber&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;minLength&#34;: 1,
              &#34;maxLength&#34;: 1023,
              &#34;description&#34;: &#34;Non-blank string uniquely identifying the tracking device&#34;
            }
          }
        }
      }
    },
    &#34;globalStage&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;required&#34;: [
        &#34;E&#34;,
        &#34;N&#34;,
        &#34;U&#34;,
        &#34;lat0&#34;,
        &#34;lon0&#34;,
        &#34;h0&#34;
      ],
      &#34;properties&#34;: {
        &#34;E&#34;: {
          &#34;type&#34;: &#34;number&#34;
        },
        &#34;N&#34;: {
          &#34;type&#34;: &#34;number&#34;
        },
        &#34;U&#34;: {
          &#34;type&#34;: &#34;number&#34;
        },
        &#34;lat0&#34;: {
          &#34;type&#34;: &#34;number&#34;
        },
        &#34;lon0&#34;: {
          &#34;type&#34;: &#34;number&#34;
        },
        &#34;h0&#34;: {
          &#34;type&#34;: &#34;number&#34;
        }
      },
      &#34;description&#34;: &#34;Position of stage origin in global ENU and geodetic coordinates (E, N, U, lat0, lon0, h0). Note this may be dynamic if the stage is inside a moving vehicle. &#34;,
      &#34;units&#34;: &#34;meter&#34;
    },
    &#34;lens&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;properties&#34;: {
        &#34;custom&#34;: {
          &#34;type&#34;: &#34;array&#34;,
          &#34;items&#34;: {
            &#34;type&#34;: &#34;number&#34;
          },
          &#34;description&#34;: &#34;This list provides optional additional custom coefficients that can  extend the existing lens model. The meaning of and how these characteristics are to be applied to a virtual camera would require negotiation between a particular producer and consumer. &#34;
        },
        &#34;distortionOffset&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;required&#34;: [
            &#34;x&#34;,
            &#34;y&#34;
          ],
          &#34;properties&#34;: {
            &#34;x&#34;: {
              &#34;type&#34;: &#34;number&#34;
            },
            &#34;y&#34;: {
              &#34;type&#34;: &#34;number&#34;
            }
          },
          &#34;description&#34;: &#34;Offset in x and y of the centre of distortion of the virtual camera&#34;,
          &#34;units&#34;: &#34;millimeter&#34;
        },
        &#34;distortionOverscan&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;minimum&#34;: 1.0,
          &#34;description&#34;: &#34;Overscan factor on lens distortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. &#34;
        },
        &#34;distortion&#34;: {
          &#34;type&#34;: &#34;array&#34;,
          &#34;minItems&#34;: 1,
          &#34;items&#34;: {
            &#34;type&#34;: &#34;object&#34;,
            &#34;additionalProperties&#34;: false,
            &#34;required&#34;: [
              &#34;radial&#34;
            ],
            &#34;properties&#34;: {
              &#34;model&#34;: {
                &#34;type&#34;: &#34;string&#34;,
                &#34;minLength&#34;: 1,
                &#34;maxLength&#34;: 1023
              },
              &#34;radial&#34;: {
                &#34;type&#34;: &#34;array&#34;,
                &#34;items&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                },
                &#34;minItems&#34;: 1
              },
              &#34;tangential&#34;: {
                &#34;type&#34;: &#34;array&#34;,
                &#34;items&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                },
                &#34;minItems&#34;: 1
              }
            }
          },
          &#34;description&#34;: &#34;A list of Distortion objects that each define the coefficients for calculating the distortion characteristics of a lens comprising radial distortion coefficients of the spherical distortion (k1-N) and the tangential distortion (p1-N). An optional key &#39;model&#39; can be used that describes the distortion model. The default is Brown-Conrady D-U (that maps Distorted to Undistorted coordinates). &#34;
        },
        &#34;encoders&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;focus&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 0.0,
              &#34;maximum&#34;: 1.0
            },
            &#34;iris&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 0.0,
              &#34;maximum&#34;: 1.0
            },
            &#34;zoom&#34;: {
              &#34;type&#34;: &#34;number&#34;,
              &#34;minimum&#34;: 0.0,
              &#34;maximum&#34;: 1.0
            }
          },
          &#34;anyOf&#34;: [
            {
              &#34;required&#34;: [
                &#34;focus&#34;
              ]
            },
            {
              &#34;required&#34;: [
                &#34;iris&#34;
              ]
            },
            {
              &#34;required&#34;: [
                &#34;zoom&#34;
              ]
            }
          ],
          &#34;description&#34;: &#34;Normalised real numbers (0-1) for focus, iris and zoom. Encoders are represented in this way (as opposed to raw integer values) to ensure values remain independent of encoder resolution, minimum and maximum (at an acceptable loss of precision). These values are only relevant in lenses with end-stops that demarcate the 0 and 1 range. Value should be provided in the following directions (if known): Focus:   0=infinite     1=closest Iris:    0=open         1=closed Zoom:    0=wide angle   1=telephoto &#34;
        },
        &#34;entrancePupilOffset&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;description&#34;: &#34;Offset of the entrance pupil relative to the nominal imaging plane (positive if the entrance pupil is located on the side of the nominal imaging plane that is towards the object, and negative otherwise). Measured in meters as in a render engine it is often applied in the virtual camera&#39;s transform chain. &#34;,
          &#34;units&#34;: &#34;meter&#34;
        },
        &#34;exposureFalloff&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;required&#34;: [
            &#34;a1&#34;
          ],
          &#34;properties&#34;: {
            &#34;a1&#34;: {
              &#34;type&#34;: &#34;number&#34;
            },
            &#34;a2&#34;: {
              &#34;type&#34;: &#34;number&#34;
            },
            &#34;a3&#34;: {
              &#34;type&#34;: &#34;number&#34;
            }
          },
          &#34;description&#34;: &#34;Coefficients for calculating the exposure fall-off (vignetting) of a lens &#34;
        },
        &#34;fStop&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;minimum&#34;: 0.0,
          &#34;description&#34;: &#34;The linear f-number of the lens, equal to the focal length divided by the diameter of the entrance pupil. &#34;
        },
        &#34;focalLength&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;minimum&#34;: 0.0,
          &#34;description&#34;: &#34;Focal length of the lens.&#34;,
          &#34;units&#34;: &#34;millimeter&#34;
        },
        &#34;focusDistance&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;exclusiveMinimum&#34;: 0.0,
          &#34;description&#34;: &#34;Focus distance/position of the lens&#34;,
          &#34;units&#34;: &#34;meter&#34;
        },
        &#34;projectionOffset&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;required&#34;: [
            &#34;x&#34;,
            &#34;y&#34;
          ],
          &#34;properties&#34;: {
            &#34;x&#34;: {
              &#34;type&#34;: &#34;number&#34;
            },
            &#34;y&#34;: {
              &#34;type&#34;: &#34;number&#34;
            }
          },
          &#34;description&#34;: &#34;Offset in x and y of the centre of perspective projection of the virtual camera &#34;,
          &#34;units&#34;: &#34;millimeter&#34;
        },
        &#34;rawEncoders&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;focus&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 4294967295
            },
            &#34;iris&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 4294967295
            },
            &#34;zoom&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 4294967295
            }
          },
          &#34;anyOf&#34;: [
            {
              &#34;required&#34;: [
                &#34;focus&#34;
              ]
            },
            {
              &#34;required&#34;: [
                &#34;iris&#34;
              ]
            },
            {
              &#34;required&#34;: [
                &#34;zoom&#34;
              ]
            }
          ],
          &#34;description&#34;: &#34;Raw encoder values for focus, iris and zoom. These values are dependent on encoder resolution and before any homing / ranging has taken place. &#34;
        },
        &#34;tStop&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;minimum&#34;: 0.0,
          &#34;description&#34;: &#34;Linear t-number of the lens, equal to the F-number of the lens divided by the square root of the transmittance of the lens. &#34;
        },
        &#34;undistortionOverscan&#34;: {
          &#34;type&#34;: &#34;number&#34;,
          &#34;minimum&#34;: 1.0,
          &#34;description&#34;: &#34;Overscan factor on lens undistortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. &#34;
        }
      }
    },
    &#34;protocol&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;properties&#34;: {
        &#34;name&#34;: {
          &#34;type&#34;: &#34;string&#34;,
          &#34;minLength&#34;: 1,
          &#34;maxLength&#34;: 1023
        },
        &#34;version&#34;: {
          &#34;type&#34;: &#34;array&#34;,
          &#34;items&#34;: {
            &#34;type&#34;: &#34;integer&#34;,
            &#34;minimum&#34;: 0,
            &#34;maximum&#34;: 9
          },
          &#34;minItems&#34;: 3,
          &#34;maxItems&#34;: 3
        }
      },
      &#34;required&#34;: [
        &#34;name&#34;,
        &#34;version&#34;
      ],
      &#34;description&#34;: &#34;Name of the protocol in which the sample is being employed, and version of that protocol &#34;
    },
    &#34;relatedSampleIds&#34;: {
      &#34;type&#34;: &#34;array&#34;,
      &#34;items&#34;: {
        &#34;type&#34;: &#34;string&#34;,
        &#34;pattern&#34;: &#34;^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$&#34;
      },
      &#34;description&#34;: &#34;List of sampleId properties of samples related to this sample. The existence of a sample with a given sampleId is not guaranteed. &#34;
    },
    &#34;sampleId&#34;: {
      &#34;type&#34;: &#34;string&#34;,
      &#34;pattern&#34;: &#34;^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$&#34;,
      &#34;description&#34;: &#34;URN serving as unique identifier of the sample in which data is being transported. &#34;
    },
    &#34;sourceId&#34;: {
      &#34;type&#34;: &#34;string&#34;,
      &#34;pattern&#34;: &#34;^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$&#34;,
      &#34;description&#34;: &#34;URN serving as unique identifier of the source from which data is being transported. &#34;
    },
    &#34;sourceNumber&#34;: {
      &#34;type&#34;: &#34;integer&#34;,
      &#34;minimum&#34;: 0,
      &#34;maximum&#34;: 4294967295,
      &#34;description&#34;: &#34;Number that identifies the index of the stream from a source from which data is being transported. This is most important in the case where a source is producing multiple streams of samples. &#34;
    },
    &#34;timing&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;properties&#34;: {
        &#34;mode&#34;: {
          &#34;type&#34;: &#34;string&#34;,
          &#34;enum&#34;: [
            &#34;internal&#34;,
            &#34;external&#34;
          ],
          &#34;description&#34;: &#34;Enumerated value indicating whether the sample transport mechanism provides inherent (&#39;external&#39;) timing, or whether the transport mechanism lacks inherent timing and so the sample must contain a PTP timestamp itself (&#39;internal&#39;) to carry timing information. &#34;
        },
        &#34;recordedTimestamp&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;seconds&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 281474976710655
            },
            &#34;nanoseconds&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 4294967295
            }
          },
          &#34;required&#34;: [
            &#34;seconds&#34;,
            &#34;nanoseconds&#34;
          ],
          &#34;description&#34;: &#34;PTP timestamp of the data recording instant, provided for convenience during playback of e.g. pre-recorded tracking data. The timestamp comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned integer (nanoseconds) &#34;,
          &#34;units&#34;: &#34;second&#34;
        },
        &#34;sampleRate&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;properties&#34;: {
            &#34;num&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 1,
              &#34;maximum&#34;: 2147483647
            },
            &#34;denom&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 1,
              &#34;maximum&#34;: 4294967295
            }
          },
          &#34;required&#34;: [
            &#34;num&#34;,
            &#34;denom&#34;
          ],
          &#34;additionalProperties&#34;: false,
          &#34;description&#34;: &#34;Sample frame rate as a rational number. Drop frame rates such as 29.97 should be represented as e.g. 30000/1001. In a variable rate system this should is estimated from the last sample delta time. &#34;
        },
        &#34;sampleTimestamp&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;properties&#34;: {
            &#34;seconds&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 281474976710655
            },
            &#34;nanoseconds&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 4294967295
            }
          },
          &#34;required&#34;: [
            &#34;seconds&#34;,
            &#34;nanoseconds&#34;
          ],
          &#34;description&#34;: &#34;PTP timestamp of the data capture instant. Note this may differ from the packet&#39;s transmission PTP timestamp. The timestamp comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned integer (nanoseconds) &#34;,
          &#34;units&#34;: &#34;second&#34;
        },
        &#34;sequenceNumber&#34;: {
          &#34;type&#34;: &#34;integer&#34;,
          &#34;minimum&#34;: 0,
          &#34;maximum&#34;: 4294967295,
          &#34;description&#34;: &#34;Integer incrementing with each sample.&#34;
        },
        &#34;synchronization&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;description&#34;: &#34;Object describing how the tracking device is synchronized for this sample.\n frequency: The frequency of a synchronization signal.This may differ from the sample frame rate for example in a genlocked tracking device. This is not required if the synchronization source is PTP or NTP. locked: Is the tracking device locked to the synchronization source offsets: Offsets in seconds between sync and sample. Critical for e.g. frame remapping, or when using different data sources for position/rotation and lens encoding present: Is the synchronization source present (a synchronization source can be present but not locked if frame rates differ for example) ptp: If the synchronization source is a PTP leader, then this object contains: - \&#34;leader\&#34;: The MAC address of the PTP leader - \&#34;offset\&#34;: The timing offset in seconds from the sample timestamp to the PTP timestamp - \&#34;domain\&#34;: The PTP domain number source: The source of synchronization must be defined as one of the following: - \&#34;genlock\&#34;: The tracking device has an external black/burst or tri-level analog sync signal that is triggering the capture of tracking samples - \&#34;videoIn\&#34;: The tracking device has an external video signal that is triggering the capture of tracking samples - \&#34;ptp\&#34;: The tracking device is locked to a PTP leader - \&#34;ntp\&#34;: The tracking device is locked to an NTP server &#34;,
          &#34;properties&#34;: {
            &#34;frequency&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;additionalProperties&#34;: false,
              &#34;required&#34;: [
                &#34;num&#34;,
                &#34;denom&#34;
              ],
              &#34;properties&#34;: {
                &#34;num&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 2147483647
                },
                &#34;denom&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 1,
                  &#34;maximum&#34;: 4294967295
                }
              }
            },
            &#34;locked&#34;: {
              &#34;type&#34;: &#34;boolean&#34;
            },
            &#34;offsets&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;additionalProperties&#34;: false,
              &#34;properties&#34;: {
                &#34;translation&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                },
                &#34;rotation&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                },
                &#34;lensEncoders&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                }
              }
            },
            &#34;present&#34;: {
              &#34;type&#34;: &#34;boolean&#34;
            },
            &#34;ptp&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;additionalProperties&#34;: false,
              &#34;properties&#34;: {
                &#34;leader&#34;: {
                  &#34;type&#34;: &#34;string&#34;,
                  &#34;pattern&#34;: &#34;(?:^[0-9a-f]{2}(?::[0-9a-f]{2}){5}$)|(?:^[0-9a-f]{2}(?:-[0-9a-f]{2}){5}$)&#34;
                },
                &#34;offset&#34;: {
                  &#34;type&#34;: &#34;number&#34;
                },
                &#34;domain&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 0,
                  &#34;maximum&#34;: 127
                }
              }
            },
            &#34;source&#34;: {
              &#34;type&#34;: &#34;string&#34;,
              &#34;enum&#34;: [
                &#34;genlock&#34;,
                &#34;videoIn&#34;,
                &#34;ptp&#34;,
                &#34;ntp&#34;
              ]
            }
          },
          &#34;required&#34;: [
            &#34;locked&#34;,
            &#34;source&#34;
          ]
        },
        &#34;timecode&#34;: {
          &#34;type&#34;: &#34;object&#34;,
          &#34;additionalProperties&#34;: false,
          &#34;required&#34;: [
            &#34;hours&#34;,
            &#34;minutes&#34;,
            &#34;seconds&#34;,
            &#34;frames&#34;,
            &#34;format&#34;
          ],
          &#34;properties&#34;: {
            &#34;hours&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 23
            },
            &#34;minutes&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 59
            },
            &#34;seconds&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 59
            },
            &#34;frames&#34;: {
              &#34;type&#34;: &#34;integer&#34;,
              &#34;minimum&#34;: 0,
              &#34;maximum&#34;: 119
            },
            &#34;format&#34;: {
              &#34;type&#34;: &#34;object&#34;,
              &#34;description&#34;: &#34;The timecode format is defined as a rational frame rate and - where a signal with sub-frames is described, such as an interlaced signal - an index of which sub-frame is referred to by the timecode. &#34;,
              &#34;required&#34;: [
                &#34;frameRate&#34;
              ],
              &#34;additionalProperties&#34;: false,
              &#34;properties&#34;: {
                &#34;frameRate&#34;: {
                  &#34;type&#34;: &#34;object&#34;,
                  &#34;additionalProperties&#34;: false,
                  &#34;required&#34;: [
                    &#34;num&#34;,
                    &#34;denom&#34;
                  ],
                  &#34;properties&#34;: {
                    &#34;num&#34;: {
                      &#34;type&#34;: &#34;integer&#34;,
                      &#34;minimum&#34;: 1,
                      &#34;maximum&#34;: 2147483647
                    },
                    &#34;denom&#34;: {
                      &#34;type&#34;: &#34;integer&#34;,
                      &#34;minimum&#34;: 1,
                      &#34;maximum&#34;: 4294967295
                    }
                  }
                },
                &#34;subFrame&#34;: {
                  &#34;type&#34;: &#34;integer&#34;,
                  &#34;minimum&#34;: 0,
                  &#34;maximum&#34;: 4294967295
                }
              }
            }
          },
          &#34;description&#34;: &#34;SMPTE timecode of the sample. Timecode is a standard for labeling individual frames of data in media systems and is useful for inter-frame synchronization. - format.frameRate: The frame rate as a rational number. Drop frame rates such as 29.97 should be represented as e.g. 30000/1001. The timecode frame rate may differ from the sample frequency. &#34;
        }
      }
    },
    &#34;tracker&#34;: {
      &#34;type&#34;: &#34;object&#34;,
      &#34;additionalProperties&#34;: false,
      &#34;properties&#34;: {
        &#34;notes&#34;: {
          &#34;type&#34;: &#34;string&#34;,
          &#34;minLength&#34;: 1,
          &#34;maxLength&#34;: 1023,
          &#34;description&#34;: &#34;Non-blank string containing notes about tracking system&#34;
        },
        &#34;recording&#34;: {
          &#34;type&#34;: &#34;boolean&#34;,
          &#34;description&#34;: &#34;Boolean indicating whether tracking system is recording data&#34;
        },
        &#34;slate&#34;: {
          &#34;type&#34;: &#34;string&#34;,
          &#34;minLength&#34;: 1,
          &#34;maxLength&#34;: 1023,
          &#34;description&#34;: &#34;Non-blank string describing the recording slate&#34;
        },
        &#34;status&#34;: {
          &#34;type&#34;: &#34;string&#34;,
          &#34;minLength&#34;: 1,
          &#34;maxLength&#34;: 1023,
          &#34;description&#34;: &#34;Non-blank string describing status of tracking system&#34;
        }
      }
    },
    &#34;transforms&#34;: {
      &#34;type&#34;: &#34;array&#34;,
      &#34;minItems&#34;: 1,
      &#34;uniqueItems&#34;: false,
      &#34;items&#34;: {
        &#34;type&#34;: &#34;object&#34;,
        &#34;additionalProperties&#34;: false,
        &#34;properties&#34;: {
          &#34;translation&#34;: {
            &#34;type&#34;: &#34;object&#34;,
            &#34;additionalProperties&#34;: false,
            &#34;properties&#34;: {
              &#34;x&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;y&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;z&#34;: {
                &#34;type&#34;: &#34;number&#34;
              }
            },
            &#34;units&#34;: &#34;meter&#34;
          },
          &#34;rotation&#34;: {
            &#34;type&#34;: &#34;object&#34;,
            &#34;additionalProperties&#34;: false,
            &#34;properties&#34;: {
              &#34;pan&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;tilt&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;roll&#34;: {
                &#34;type&#34;: &#34;number&#34;
              }
            },
            &#34;units&#34;: &#34;degree&#34;
          },
          &#34;scale&#34;: {
            &#34;type&#34;: &#34;object&#34;,
            &#34;additionalProperties&#34;: false,
            &#34;properties&#34;: {
              &#34;x&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;y&#34;: {
                &#34;type&#34;: &#34;number&#34;
              },
              &#34;z&#34;: {
                &#34;type&#34;: &#34;number&#34;
              }
            }
          },
          &#34;id&#34;: {
            &#34;type&#34;: &#34;string&#34;,
            &#34;minLength&#34;: 1,
            &#34;maxLength&#34;: 1023
          }
        },
        &#34;required&#34;: [
          &#34;translation&#34;,
          &#34;rotation&#34;
        ]
      },
      &#34;description&#34;: &#34;A list of transforms. Transforms are composed in order with the last in the list representing the X,Y,Z in meters of camera sensor relative to stage origin. The Z axis points upwards and the coordinate system is right-handed. Y points in the forward camera direction (when pan, tilt and roll are zero). For example in an LED volume Y would point towards the centre of the LED wall and so X would point to camera-right. Rotation expressed as euler angles in degrees of the camera sensor relative to stage origin Rotations are intrinsic and are measured around the axes ZXY, commonly referred to as [pan, tilt, roll] Notes on Euler angles: Euler angles are human readable and unlike quarternions, provide the ability for cycles (with angles &gt;360 or &lt;0 degrees). Where a tracking system is providing the pose of a virtual camera, gimbal lock does not present the physical challenges of a robotic system. Conversion to and from quarternions is trivial with an acceptable loss of precision. &#34;,
      &#34;units&#34;: &#34;meter / degree&#34;
    }
  }
}</code></pre></div>

            <h2>Future additions</h2>
            <p>In the future RIS intends to add support for:</p>
            <ul>
                <li>Improved session and transport specifications and reference examples</li>
                <li>SMPTE 2110 -41 and -42 integration</li>
                <li>Anamorphic lens mathematics and enhanced vignette model (in OpenLensIO)</li>
                <li>Device discovery</li>
            </ul>
        </div>
    </div>
    <div class="footer">
        <div class="inner">
            <p><strong>Authored by SMPTE RIS OSVP</strong></p>
            <img src="img/RISLogoFinalwhiteColor.png" class="footerLogo" />
            <p>The OpenTrackIO documentation is generated by <a href="https://github.com/SMPTE/ris-osvp-metadata-camdkit" target="_blank">CamDKit</a></p>
            <p>Authors: 
                <ul>
                    <li><a href="mailto:info@mo-sys.com">James Uren</a>, Mo-Sys</li>
                    <li><a href="mailto:marcus@originalsyndicate.com">Marcus Bengtsson</a>, Original Syndicate</li>
                    <li><a href="mailto:steve@conceptoverdrive.com">Steve Rosenbluth</a>, Concept Overdrive</li>
                    <li><a href="ailto:info@trackmen.de">Hendrik Fehlis</a>, TrackMen</li>
                </ul>
            </p>
        </div>
    </div>
    
<script>
    var coll = document.getElementsByClassName("collapsible");
    var i;
    
    for (i = 0; i < coll.length; i++) {
      coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
          content.style.display = "none";
        } else {
          content.style.display = "block";
        }
      });
    }
</script>
</body>
</html>