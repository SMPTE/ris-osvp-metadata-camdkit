{
  "$id": "https://opentrackio.org/schema.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "static": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "camera": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "activeSensorPhysicalDimensions": {
              "type": "object",
              "additionalProperties": false,
              "required": [
                "height",
                "width"
              ],
              "properties": {
                "height": {
                  "type": "number",
                  "minimum": 0.0
                },
                "width": {
                  "type": "number",
                  "minimum": 0.0
                }
              },
              "description": "Height and width of the active area of the camera sensor in microns ",
              "units": "millimeter"
            },
            "activeSensorResolution": {
              "type": "object",
              "additionalProperties": false,
              "required": [
                "height",
                "width"
              ],
              "properties": {
                "height": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 2147483647
                },
                "width": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 2147483647
                }
              },
              "description": "Photosite resolution of the active area of the camera sensor in pixels ",
              "units": "pixel"
            },
            "anamorphicSqueeze": {
              "type": "object",
              "properties": {
                "num": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 2147483647
                },
                "denom": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 4294967295
                }
              },
              "required": [
                "num",
                "denom"
              ],
              "additionalProperties": false,
              "description": "Nominal ratio of height to width of the image of an axis-aligned square captured by the camera sensor. It can be used to de-squeeze images but is not however an exact number over the entire captured area due to a lens' intrinsic analog nature. "
            },
            "firmwareVersion": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying camera firmware version"
            },
            "label": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string containing user-determined camera identifier"
            },
            "make": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string naming camera manufacturer"
            },
            "model": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying camera model"
            },
            "serialNumber": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string uniquely identifying the camera"
            },
            "captureFrameRate": {
              "type": "object",
              "properties": {
                "num": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 2147483647
                },
                "denom": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 4294967295
                }
              },
              "required": [
                "num",
                "denom"
              ],
              "additionalProperties": false,
              "description": "Capture frame rate of the camera",
              "units": "hertz"
            },
            "fdlLink": {
              "type": "string",
              "pattern": "^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$",
              "description": "URN identifying the ASC Framing Decision List used by the camera. "
            },
            "isoSpeed": {
              "type": "integer",
              "minimum": 1,
              "maximum": 4294967295,
              "description": "Arithmetic ISO scale as defined in ISO 12232"
            },
            "shutterAngle": {
              "type": "number",
              "minimum": 0.0,
              "maximum": 360.0,
              "description": "Shutter speed as a fraction of the capture frame rate. The shutter speed (in units of 1/s) is equal to the value of the parameter divided by 360 times the capture frame rate. ",
              "units": "degree"
            }
          }
        },
        "duration": {
          "type": "object",
          "properties": {
            "num": {
              "type": "integer",
              "minimum": 0,
              "maximum": 2147483647
            },
            "denom": {
              "type": "integer",
              "minimum": 1,
              "maximum": 4294967295
            }
          },
          "required": [
            "num",
            "denom"
          ],
          "additionalProperties": false,
          "description": "Duration of the clip",
          "units": "second"
        },
        "lens": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "distortionProjection": {
              "type": "boolean",
              "description": "Indicator that the OpenLensIO distortion model is the Projection Characterization, not the Field-Of-View Characterization. This is  primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. "
            },
            "distortionOverscanMax": {
              "type": "number",
              "minimum": 1.0,
              "description": "Static maximum overscan factor on lens distortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. "
            },
            "firmwareVersion": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying lens firmware version"
            },
            "make": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string naming lens manufacturer"
            },
            "model": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying lens model"
            },
            "nominalFocalLength": {
              "type": "number",
              "minimum": 0.0,
              "description": "Nominal focal length of the lens. The number printed on the side of a prime lens, e.g. 50 mm, and undefined in the case of a zoom lens. ",
              "units": "millimeter"
            },
            "serialNumber": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string uniquely identifying the lens"
            },
            "undistortionOverscanMax": {
              "type": "number",
              "minimum": 1.0,
              "description": "Static maximum overscan factor on lens undistortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. "
            }
          }
        },
        "tracker": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "firmwareVersion": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying tracking device firmware version"
            },
            "make": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string naming tracking device manufacturer"
            },
            "model": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string identifying tracking device model"
            },
            "serialNumber": {
              "type": "string",
              "minLength": 1,
              "maxLength": 1023,
              "description": "Non-blank string uniquely identifying the tracking device"
            }
          }
        }
      }
    },
    "globalStage": {
      "type": "object",
      "additionalProperties": false,
      "required": [
        "E",
        "N",
        "U",
        "lat0",
        "lon0",
        "h0"
      ],
      "properties": {
        "E": {
          "type": "number"
        },
        "N": {
          "type": "number"
        },
        "U": {
          "type": "number"
        },
        "lat0": {
          "type": "number"
        },
        "lon0": {
          "type": "number"
        },
        "h0": {
          "type": "number"
        }
      },
      "description": "Position of stage origin in global ENU and geodetic coordinates (E, N, U, lat0, lon0, h0). Note this may be dynamic if the stage is inside a moving vehicle. ",
      "units": "meter"
    },
    "lens": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "custom": {
          "type": "array",
          "items": {
            "type": "number"
          },
          "description": "Until the OpenLensIO model is finalised, this list provides custom coefficients for a particular lens model e.g. undistortion, anamorphic etc "
        },
        "distortionOffset": {
          "type": "object",
          "additionalProperties": false,
          "required": [
            "x",
            "y"
          ],
          "properties": {
            "x": {
              "type": "number"
            },
            "y": {
              "type": "number"
            }
          },
          "description": "Offset in x and y of the centre of distortion of the virtual camera ",
          "units": "millimeter"
        },
        "distortionOverscan": {
          "type": "number",
          "minimum": 1.0,
          "description": "Overscan factor on lens distortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. "
        },
        "distortion": {
          "type": "array",
          "minItems": 1,
          "items": {
            "type": "object",
            "additionalProperties": false,
            "required": [
              "radial"
            ],
            "properties": {
              "model": {
                "type": "string"
              },
              "radial": {
                "type": "array",
                "items": {
                  "type": "number"
                },
                "minLength": 1
              },
              "tangential": {
                "type": "array",
                "items": {
                  "type": "number"
                },
                "minLength": 1
              }
            }
          },
          "description": "A list of Distortion objects that each define the coefficients for calculating the distortion characteristics of a lens comprising radial distortion coefficients of the spherical distortion (k1-N) and the tangential distortion (p1-N). An optional key 'model' can be used that describes the distortion model. The default is Brown-Conrady D-U (that maps Distorted to Undistorted coordinates). "
        },
        "encoders": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "focus": {
              "type": "number",
              "minimum": 0.0,
              "maximum": 1.0
            },
            "iris": {
              "type": "number",
              "minimum": 0.0,
              "maximum": 1.0
            },
            "zoom": {
              "type": "number",
              "minimum": 0.0,
              "maximum": 1.0
            }
          },
          "anyOf": [
            {
              "required": [
                "focus"
              ]
            },
            {
              "required": [
                "iris"
              ]
            },
            {
              "required": [
                "zoom"
              ]
            }
          ],
          "description": " Normalised real numbers (0-1) for focus, iris and zoom. Encoders are represented in this way (as opposed to raw integer   values) to ensure values remain independent of encoder resolution,   mininum and maximum (at an acceptable loss of precision). These values are only relevant in lenses with end-stops that   demarcate the 0 and 1 range. Value should be provided in the following directions (if known):   Focus:   0=infinite     1=closest   Iris:    0=open         1=closed   Zoom:    0=wide angle   1=telephoto "
        },
        "entrancePupilOffset": {
          "type": "number",
          "description": "Offset of the entrance pupil relative to the nominal imaging plane (positive if the entrance pupil is located on the side of the nominal imaging plane that is towards the object, and negative otherwise). Measured in meters as in a render engine it is often applied in the virtual camera's transform chain. ",
          "units": "meter"
        },
        "exposureFalloff": {
          "type": "object",
          "additionalProperties": false,
          "required": [
            "a1"
          ],
          "properties": {
            "a1": {
              "type": "number"
            },
            "a2": {
              "type": "number"
            },
            "a3": {
              "type": "number"
            }
          },
          "description": "Coefficients for calculating the exposure fall-off (vignetting) of a lens "
        },
        "fStop": {
          "type": "number",
          "minimum": 0.0,
          "description": "The linear f-number of the lens, equal to the focal length divided by the diameter of the entrance pupil. "
        },
        "focalLength": {
          "type": "number",
          "minimum": 0.0,
          "description": "Focal length of the lens.",
          "units": "millimeter"
        },
        "focusDistance": {
          "type": "number",
          "minimum": 0.0,
          "description": "Focus distance/position of the lens",
          "units": "meter"
        },
        "projectionOffset": {
          "type": "object",
          "additionalProperties": false,
          "required": [
            "x",
            "y"
          ],
          "properties": {
            "x": {
              "type": "number"
            },
            "y": {
              "type": "number"
            }
          },
          "description": "Offset in x and y of the centre of perspective projection of the virtual camera ",
          "units": "millimeter"
        },
        "rawEncoders": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "focus": {
              "type": "integer",
              "minimum": 0
            },
            "iris": {
              "type": "integer",
              "minimum": 0
            },
            "zoom": {
              "type": "integer",
              "minimum": 0
            }
          },
          "anyOf": [
            {
              "required": [
                "focus"
              ]
            },
            {
              "required": [
                "iris"
              ]
            },
            {
              "required": [
                "zoom"
              ]
            }
          ],
          "description": " Raw encoder values for focus, iris and zoom. These values are dependent on encoder resolution and before any   homing / ranging has taken place. "
        },
        "tStop": {
          "type": "number",
          "minimum": 0.0,
          "description": "Linear t-number of the lens, equal to the F-number of the lens divided by the square root of the transmittance of the lens. "
        },
        "undistortionOverscan": {
          "type": "number",
          "minimum": 1.0,
          "description": "Overscan factor on lens undistortion. This is primarily relevant when storing overscan values, not in transmission as the overscan should be calculated by the consumer. "
        }
      }
    },
    "protocol": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "name": {
          "type": "string",
          "minLength": 1,
          "maxLength": 1023
        },
        "version": {
          "type": "array",
          "items": {
            "type": "integer",
            "minValue": 0,
            "maxValue": 9
          },
          "minItems": 3,
          "maxItems": 3
        }
      },
      "description": "Name of the protocol in which the sample is being employed, and version of that protocol "
    },
    "relatedSampleIds": {
      "type": "array",
      "items": {
        "type": "string",
        "pattern": "^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$"
      },
      "description": "List of sampleId properties of samples related to this sample. The existence of a sample with a given sampleId is not guaranteed. "
    },
    "sampleId": {
      "type": "string",
      "pattern": "^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$",
      "description": "URN serving as unique identifier of the sample in which data is being transported. "
    },
    "sourceId": {
      "type": "string",
      "pattern": "^urn:uuid:[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$",
      "description": "URN serving as unique identifier of the source from which data is being transported. "
    },
    "sourceNumber": {
      "type": "integer",
      "minimum": 0,
      "maximum": 4294967295,
      "description": "Number that identifies the index of the stream from a source from which data is being transported. This is most important in the case where a source is producing multiple streams of samples. "
    },
    "timing": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "mode": {
          "type": "string",
          "enum": [
            "internal",
            "external"
          ],
          "description": "Enumerated value indicating whether the sample transport mechanism   provides inherent ('external') timing, or whether the transport   mechanism lacks inherent timing and so the sample must contain a PTP   timestamp itself ('internal') to carry timing information. "
        },
        "recordedTimestamp": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "seconds": {
              "type": "integer",
              "minimum": 0,
              "maximum": 281474976710655
            },
            "nanoseconds": {
              "type": "integer",
              "minimum": 0,
              "maximum": 4294967295
            }
          },
          "required": [
            "seconds",
            "nanoseconds"
          ],
          "description": " PTP timestamp of the data recording instant, provided for convenience   during playback of e.g. pre-recorded tracking data. The timestamp   comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned   integer (nanoseconds) ",
          "units": "second"
        },
        "sampleRate": {
          "type": "object",
          "properties": {
            "num": {
              "type": "integer",
              "minimum": 0,
              "maximum": 2147483647
            },
            "denom": {
              "type": "integer",
              "minimum": 1,
              "maximum": 4294967295
            }
          },
          "required": [
            "num",
            "denom"
          ],
          "additionalProperties": false,
          "description": "Sample frame rate as a rational number. Drop frame rates such as 29.97 should be represented as e.g. 30000/1001. In a variable rate system this should is estimated from the last sample delta time. "
        },
        "sampleTimestamp": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "seconds": {
              "type": "integer",
              "minimum": 0,
              "maximum": 281474976710655
            },
            "nanoseconds": {
              "type": "integer",
              "minimum": 0,
              "maximum": 4294967295
            }
          },
          "required": [
            "seconds",
            "nanoseconds"
          ],
          "description": "PTP timestamp of the data capture instant. Note this may differ   from the packet's transmission PTP timestamp. The timestamp   comprises a 48-bit unsigned integer (seconds), a 32-bit unsigned   integer (nanoseconds) ",
          "units": "second"
        },
        "sequenceNumber": {
          "type": "integer",
          "minimum": 0,
          "maximum": 4294967295,
          "description": "Integer incrementing with each sample."
        },
        "synchronization": {
          "type": "object",
          "additionalProperties": false,
          "description": "Object describing how the tracking device is synchronized for this sample.\n frequency: The frequency of a synchronization signal.This may differ from the sample frame rate for example in a genlocked tracking device. This is not required if the synchronization source is PTP or NTP. locked: Is the tracking device locked to the synchronization source offsets: Offsets in seconds between sync and sample. Critical for e.g. frame remapping, or when using different data sources for position/rotation and lens encoding present: Is the synchronization source present (a synchronization source can be present but not locked if frame rates differ for example) ptp: If the synchronization source is a PTP master, then this object contains: - \"master\": The MAC address of the PTP master - \"offset\": The timing offset in seconds from the sample timestamp to the PTP timestamp - \"domain\": The PTP domain number source: The source of synchronization must be defined as one of the following: - \"genlock\": The tracking device has an external black/burst or tri-level analog sync signal that is triggering the capture of tracking samples - \"videoIn\": The tracking device has an external video signal that is triggering the capture of tracking samples - \"ptp\": The tracking device is locked to a PTP master - \"ntp\": The tracking device is locked to an NTP server ",
          "properties": {
            "frequency": {
              "type": "object",
              "additionalProperties": false,
              "required": [
                "num",
                "denom"
              ],
              "properties": {
                "num": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 4294967295
                },
                "denom": {
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 4294967295
                }
              }
            },
            "locked": {
              "type": "boolean"
            },
            "offsets": {
              "type": "object",
              "additionalProperties": false,
              "properties": {
                "translation": {
                  "type": "number"
                },
                "rotation": {
                  "type": "number"
                },
                "lensEncoders": {
                  "type": "number"
                }
              }
            },
            "present": {
              "type": "boolean"
            },
            "ptp": {
              "type": "object",
              "additionalProperties": false,
              "properties": {
                "master": {
                  "type": "string",
                  "pattern": "^([A-F0-9]{2}:){5}[A-F0-9]{2}$"
                },
                "offset": {
                  "type": "number"
                },
                "domain": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 127
                }
              }
            },
            "source": {
              "type": "string",
              "enum": [
                "genlock",
                "videoIn",
                "ptp",
                "ntp"
              ]
            }
          },
          "required": [
            "locked",
            "source"
          ]
        },
        "timecode": {
          "type": "object",
          "additionalProperties": false,
          "required": [
            "hours",
            "minutes",
            "seconds",
            "frames",
            "format"
          ],
          "properties": {
            "hours": {
              "type": "integer",
              "minimum": 0,
              "maximum": 23
            },
            "minutes": {
              "type": "integer",
              "minimum": 0,
              "maximum": 59
            },
            "seconds": {
              "type": "integer",
              "minimum": 0,
              "maximum": 59
            },
            "frames": {
              "type": "integer",
              "minimum": 0,
              "maximum": 119
            },
            "format": {
              "type": "object",
              "description": "The timecode format is defined as a rational frame rate and - where a signal with sub-frames is described, such as an interlaced signal - an index of which sub-frame is referred to by the timecode. ",
              "required": [
                "frameRate"
              ],
              "additionalProperties": false,
              "properties": {
                "frameRate": {
                  "type": "object",
                  "additionalProperties": false,
                  "required": [
                    "num",
                    "denom"
                  ],
                  "properties": {
                    "num": {
                      "type": "integer",
                      "minimum": 1,
                      "maximum": 4294967295
                    },
                    "denom": {
                      "type": "integer",
                      "minimum": 1,
                      "maximum": 4294967295
                    }
                  }
                },
                "subFrame": {
                  "type": "integer",
                  "minimum": 0,
                  "maximum": 4294967295
                }
              }
            }
          },
          "description": "SMPTE timecode of the sample. Timecode is a standard for labeling individual frames of data in media systems and is useful for inter-frame synchronization.  - format.frameRate: The frame rate as a rational number. Drop frame rates such as 29.97 should be represented as e.g. 30000/1001. The timecode frame rate may differ from the sample frequency. "
        }
      }
    },
    "tracker": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "notes": {
          "type": "string",
          "minLength": 1,
          "maxLength": 1023,
          "description": "Non-blank string containing notes about tracking system"
        },
        "recording": {
          "type": "boolean",
          "description": "Boolean indicating whether tracking system is recording data"
        },
        "slate": {
          "type": "string",
          "minLength": 1,
          "maxLength": 1023,
          "description": "Non-blank string describing the recording slate"
        },
        "status": {
          "type": "string",
          "minLength": 1,
          "maxLength": 1023,
          "description": "Non-blank string describing status of tracking system"
        }
      }
    },
    "transforms": {
      "type": "array",
      "minItems": 1,
      "uniqueItems": false,
      "items": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "translation": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "x": {
                "type": "number"
              },
              "y": {
                "type": "number"
              },
              "z": {
                "type": "number"
              }
            },
            "units": "meter"
          },
          "rotation": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "pan": {
                "type": "number"
              },
              "tilt": {
                "type": "number"
              },
              "roll": {
                "type": "number"
              }
            },
            "units": "degree"
          },
          "scale": {
            "type": "object",
            "additionalProperties": false,
            "properties": {
              "x": {
                "type": "number"
              },
              "y": {
                "type": "number"
              },
              "z": {
                "type": "number"
              }
            }
          },
          "id": {
            "type": "string",
            "minLength": 1,
            "maxLength": 1023
          },
          "parentId": {
            "type": "string",
            "minLength": 1,
            "maxLength": 1023
          }
        },
        "required": [
          "translation",
          "rotation"
        ]
      },
      "description": "A list of transforms. Transforms can have a id and parentId that can be used to compose a transform hierarchy. In the case of multiple children their transforms should be processed in their order in the array. X,Y,Z in meters of camera sensor relative to stage origin. The Z axis points upwards and the coordinate system is right-handed. Y points in the forward camera direction (when pan, tilt and roll are zero). For example in an LED volume Y would point towards the centre of the LED wall and so X would point to camera-right. Rotation expressed as euler angles in degrees of the camera sensor relative to stage origin Rotations are intrinsic and are measured around the axes ZXY, commonly referred to as [pan, tilt, roll] Notes on Euler angles: Euler angles are human readable and unlike quarternions, provide the ability for cycles (with angles >360 or <0 degrees). Where a tracking system is providing the pose of a virtual camera, gimbal lock does not present the physical challenges of a robotic system. Conversion to and from quarternions is trivial with an acceptable loss of precision ",
      "units": "meter / degree"
    }
  }
}